#!/usr/bin/env python3
"""
Ã‰valuation complÃ¨te du modÃ¨le Portfolio RL formÃ© sur Kaggle
Conforme aux spÃ©cifications de modelisation.pdf
"""

import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuration des graphiques
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# Import des modules locaux
from environment import PortfolioEnv
from agent import SACAgent
from models import create_sac_models
from config import Config


def main():
    """
    Fonction principale d'Ã©valuation du modÃ¨le Kaggle
    """
    print("ðŸŽ¯ Ã‰VALUATION DU MODÃˆLE PORTFOLIO RL FORMÃ‰ SUR KAGGLE")
    print("=" * 60)
    
    # VÃ©rifier que le modÃ¨le existe
    model_path = "models/sac_portfolio_agent_kaggle.pth"
    if not os.path.exists(model_path):
        print(f"âŒ ModÃ¨le non trouvÃ©: {model_path}")
        return
    
    try:
        # Chargement des donnÃ©es
        print("\nðŸ“ Chargement des donnÃ©es d'actions...")
        actions_data = pd.read_excel('datas/actions_secteurs_pays.xlsx')
        available_tickers = actions_data['Ticker'].tolist()
        
        # SÃ©lectionner les tickers pour l'Ã©valuation (6 premiers pour test)
        test_tickers = available_tickers[:6]
        
        print(f"   âœ… {len(available_tickers)} tickers disponibles")
        print(f"   ðŸŽ¯ Ã‰valuation sur: {test_tickers}")
        
        # CrÃ©er l'environnement d'Ã©valuation
        print(f"\nðŸ”§ Configuration de l'environnement d'Ã©valuation...")
        
        env = PortfolioEnv(
            tickers=test_tickers,
            start_date='2019-01-01',
            end_date='2019-12-31'
        )
        
        # Obtenir les dimensions
        obs_dim = env.observation_space.shape[0]
        action_dim = env.action_space.shape[0]
        
        print(f"   - Observation space: {obs_dim} dimensions")
        print(f"   - Action space: {action_dim} dimensions") 
        print(f"   - Assets valides: {env.valid_tickers}")
        print(f"   - PÃ©riodes: {len(env.data)} pas de temps")
        
        # CrÃ©er et charger le modÃ¨le
        print(f"\nðŸ¤– Chargement du modÃ¨le SAC Kaggle...")
        
        # CrÃ©er l'agent
        agent = SACAgent(
            state_dim=obs_dim,
            action_dim=action_dim,
            lr_actor=Config.SAC_LR_ACTOR,
            lr_critic=Config.SAC_LR_CRITIC,
            tau=Config.SAC_TAU,
            gamma=Config.SAC_GAMMA,
            alpha=Config.SAC_ALPHA
        )
        
        # Charger les poids du modÃ¨le Kaggle
        try:
            checkpoint = torch.load(model_path, map_location='cpu')
            
            if isinstance(checkpoint, dict):
                if 'actor_state_dict' in checkpoint:
                    agent.actor.load_state_dict(checkpoint['actor_state_dict'])
                    agent.critic_1.load_state_dict(checkpoint['critic_1_state_dict'])
                    agent.critic_2.load_state_dict(checkpoint['critic_2_state_dict'])
                    print(f"   âœ… ModÃ¨le chargÃ© avec succÃ¨s")
                else:
                    print(f"   âš ï¸ Format de checkpoint non reconnu")
            else:
                print(f"   âš ï¸ Utilisation du modÃ¨le initialisÃ©")
                
        except Exception as e:
            print(f"   âš ï¸ Erreur de chargement: {e}")
            print(f"   ðŸ”„ Utilisation du modÃ¨le initialisÃ©")
        
        # Mettre en mode Ã©valuation
        agent.actor.eval()
        agent.critic_1.eval() 
        agent.critic_2.eval()
        
        # Ã‰valuation sur plusieurs Ã©pisodes
        print(f"\nðŸ“Š DÃ©but de l'Ã©valuation (3 Ã©pisodes)...")
        
        os.makedirs('results', exist_ok=True)
        all_results = []
        
        for episode in range(3):
            print(f"\nðŸŽ® Ã‰pisode {episode + 1}/3")
            
            # Reset de l'environnement
            obs = env.reset()
            terminated = False
            truncated = False
            step = 0
            
            episode_data = {
                'episode': episode,
                'portfolio_values': [],
                'rewards': [],
                'actions': [],
                'allocations': [],
                'transaction_costs': []
            }
            
            initial_value = env._calculate_portfolio_value()
            episode_data['portfolio_values'].append(initial_value)
            
            while not (terminated or truncated):
                # Action de l'agent
                with torch.no_grad():
                    obs_tensor = torch.FloatTensor(obs).unsqueeze(0)
                    action = agent.select_action(obs_tensor, evaluate=True)
                
                # ExÃ©cuter l'action
                next_obs, reward, terminated, truncated, info = env.step(action)
                
                # Collecter les donnÃ©es
                episode_data['rewards'].append(reward)
                episode_data['actions'].append(action.copy())
                episode_data['allocations'].append(env.current_weights.copy())
                
                portfolio_value = env._calculate_portfolio_value()
                episode_data['portfolio_values'].append(portfolio_value)
                
                if hasattr(env, 'transaction_costs_history') and env.transaction_costs_history:
                    episode_data['transaction_costs'].append(env.transaction_costs_history[-1])
                else:
                    episode_data['transaction_costs'].append(0.0)
                
                obs = next_obs
                step += 1
                
                if step % 20 == 0:
                    print(f"   Step {step}: Value={portfolio_value:8.2f}, Reward={reward:7.4f}")
            
            # Calculer les mÃ©triques de l'Ã©pisode
            values = episode_data['portfolio_values']
            returns = [(values[i]/values[i-1] - 1) for i in range(1, len(values))]
            
            total_return = (values[-1] / values[0]) - 1 if len(values) > 1 else 0
            sharpe_ratio = np.mean(returns) / (np.std(returns) + 1e-8) if returns else 0
            
            # Drawdown
            peak = values[0]
            max_dd = 0
            for value in values[1:]:
                if value > peak:
                    peak = value
                else:
                    dd = (peak - value) / peak
                    max_dd = max(max_dd, dd)
            
            episode_metrics = {
                'total_return': total_return,
                'sharpe_ratio': sharpe_ratio, 
                'max_drawdown': max_dd,
                'mean_reward': np.mean(episode_data['rewards']),
                'total_transaction_costs': np.sum(episode_data['transaction_costs'])
            }
            
            episode_data['metrics'] = episode_metrics
            all_results.append(episode_data)
            
            print(f"   âœ… Ã‰pisode {episode + 1} terminÃ©:")
            print(f"      - Steps: {step}")
            print(f"      - Rendement: {total_return:.2%}")
            print(f"      - Sharpe: {sharpe_ratio:.3f}")
            print(f"      - Max DD: {max_dd:.2%}")
        
        # GÃ©nÃ©rer les graphiques
        print(f"\nðŸ“ˆ GÃ©nÃ©ration des visualisations...")
        generate_evaluation_plots(all_results, env)
        
        # GÃ©nÃ©rer le rapport
        print(f"\nðŸ“‹ GÃ©nÃ©ration du rapport...")
        generate_evaluation_report(all_results, env)
        
        # RÃ©sumÃ© final
        avg_return = np.mean([ep['metrics']['total_return'] for ep in all_results])
        avg_sharpe = np.mean([ep['metrics']['sharpe_ratio'] for ep in all_results])
        avg_dd = np.mean([ep['metrics']['max_drawdown'] for ep in all_results])
        
        print(f"\n" + "="*60)
        print(f"ðŸŽ¯ RÃ‰SUMÃ‰ DE L'Ã‰VALUATION - MODÃˆLE KAGGLE")
        print("="*60)
        print(f"ðŸ“Š 3 Ã©pisodes Ã©valuÃ©s")
        print(f"ðŸ“ˆ Rendement moyen: {avg_return:.2%}")
        print(f"âš¡ Sharpe moyen: {avg_sharpe:.3f}")
        print(f"ðŸ“‰ Drawdown moyen: {avg_dd:.2%}")
        print("="*60)
        print("âœ… Ã‰valuation terminÃ©e avec succÃ¨s!")
        
    except Exception as e:
        print(f"\nâŒ Erreur lors de l'Ã©valuation: {e}")
        import traceback
        traceback.print_exc()


def generate_evaluation_plots(all_results, env):
    """
    GÃ©nÃ¨re les graphiques d'Ã©valuation
    """
    # 1. Performance des portfolios
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # Valeurs du portfolio
    for i, ep in enumerate(all_results):
        values = ep['portfolio_values']
        steps = range(len(values))
        ax1.plot(steps, values, alpha=0.7, label=f'Ã‰pisode {i+1}')
    
    ax1.set_title('Ã‰volution de la valeur du portfolio', fontweight='bold')
    ax1.set_xlabel('Pas de temps')
    ax1.set_ylabel('Valeur du portfolio')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Rendements cumulÃ©s
    for i, ep in enumerate(all_results):
        values = ep['portfolio_values']
        if len(values) > 1:
            cum_returns = [(v / values[0] - 1) * 100 for v in values]
            steps = range(len(cum_returns))
            ax2.plot(steps, cum_returns, alpha=0.7, label=f'Ã‰pisode {i+1}')
    
    ax2.set_title('Rendements cumulÃ©s (%)', fontweight='bold')
    ax2.set_xlabel('Pas de temps')
    ax2.set_ylabel('Rendement cumulÃ© (%)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Rewards
    for i, ep in enumerate(all_results):
        rewards = ep['rewards']
        steps = range(len(rewards))
        ax3.plot(steps, rewards, alpha=0.7, label=f'Ã‰pisode {i+1}')
    
    ax3.set_title('Ã‰volution des rewards', fontweight='bold')
    ax3.set_xlabel('Pas de temps')
    ax3.set_ylabel('Reward')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # MÃ©triques par Ã©pisode
    episodes = range(1, len(all_results) + 1)
    returns = [ep['metrics']['total_return'] * 100 for ep in all_results]
    sharpes = [ep['metrics']['sharpe_ratio'] for ep in all_results]
    
    ax4_twin = ax4.twinx()
    
    bars1 = ax4.bar([x - 0.2 for x in episodes], returns, 
                   width=0.4, alpha=0.7, label='Rendement (%)', color='green')
    bars2 = ax4_twin.bar([x + 0.2 for x in episodes], sharpes, 
                       width=0.4, alpha=0.7, label='Sharpe', color='blue')
    
    ax4.set_title('MÃ©triques par Ã©pisode', fontweight='bold')
    ax4.set_xlabel('Ã‰pisode')
    ax4.set_ylabel('Rendement (%)', color='green')
    ax4_twin.set_ylabel('Sharpe ratio', color='blue')
    ax4.set_xticks(episodes)
    
    plt.tight_layout()
    plt.savefig('results/evaluation_performance.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. Allocations
    n_assets = len(env.valid_tickers)
    colors = plt.cm.Set3(np.linspace(0, 1, n_assets))
    
    fig, axes = plt.subplots(len(all_results), 1, figsize=(12, 4*len(all_results)))
    if len(all_results) == 1:
        axes = [axes]
    
    for ep_idx, ep in enumerate(all_results):
        allocations = np.array(ep['allocations'])
        steps = range(len(allocations))
        
        axes[ep_idx].stackplot(steps, *allocations.T, labels=env.valid_tickers, 
                             colors=colors, alpha=0.8)
        axes[ep_idx].set_title(f'Allocations - Ã‰pisode {ep_idx + 1}', fontweight='bold')
        axes[ep_idx].set_xlabel('Pas de temps')
        axes[ep_idx].set_ylabel('Allocation')
        axes[ep_idx].set_ylim(0, 1)
        axes[ep_idx].legend(loc='center left', bbox_to_anchor=(1, 0.5))
        axes[ep_idx].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('results/evaluation_allocations.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("   âœ… Graphiques sauvegardÃ©s dans 'results/'")


def generate_evaluation_report(all_results, env):
    """
    GÃ©nÃ¨re le rapport d'Ã©valuation
    """
    report = []
    report.append("# ðŸŽ¯ RAPPORT D'Ã‰VALUATION - MODÃˆLE PORTFOLIO RL KAGGLE")
    report.append("=" * 60)
    report.append(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    # Configuration
    report.append("## ðŸ”§ Configuration")
    report.append(f"- Assets: {', '.join(env.valid_tickers)}")
    report.append(f"- Nombre d'assets: {len(env.valid_tickers)}")
    report.append(f"- PÃ©riodes: {len(env.data)} pas de temps")
    report.append(f"- Dimensions Ã©tat: {env.observation_space.shape[0]}")
    report.append("")
    
    # MÃ©triques agrÃ©gÃ©es
    avg_return = np.mean([ep['metrics']['total_return'] for ep in all_results])
    avg_sharpe = np.mean([ep['metrics']['sharpe_ratio'] for ep in all_results])
    avg_dd = np.mean([ep['metrics']['max_drawdown'] for ep in all_results])
    avg_reward = np.mean([ep['metrics']['mean_reward'] for ep in all_results])
    
    report.append("## ðŸ“Š MÃ©triques agrÃ©gÃ©es")
    report.append(f"- Ã‰pisodes: {len(all_results)}")
    report.append(f"- Rendement moyen: {avg_return:.2%}")
    report.append(f"- Sharpe moyen: {avg_sharpe:.3f}")
    report.append(f"- Drawdown moyen: {avg_dd:.2%}")
    report.append(f"- Reward moyen: {avg_reward:.4f}")
    report.append("")
    
    # DÃ©tails par Ã©pisode
    report.append("## ðŸ“ˆ DÃ©tails par Ã©pisode")
    for i, ep in enumerate(all_results):
        metrics = ep['metrics']
        report.append(f"### Ã‰pisode {i + 1}")
        report.append(f"- Rendement: {metrics['total_return']:.2%}")
        report.append(f"- Sharpe: {metrics['sharpe_ratio']:.3f}")
        report.append(f"- Max DD: {metrics['max_drawdown']:.2%}")
        report.append(f"- Reward moyen: {metrics['mean_reward']:.4f}")
        report.append(f"- CoÃ»ts: {metrics['total_transaction_costs']:.2f}")
        report.append("")
    
    # Framework mathÃ©matique
    report.append("## ðŸ§® Framework mathÃ©matique implÃ©mentÃ©")
    report.append("- âœ… Espace d'Ã©tat amÃ©liorÃ© (7 composants)")
    report.append("- âœ… RÃ©compense multi-composants")
    report.append("- âœ… ModÃ©lisation stochastique des risques")
    report.append("- âœ… CoÃ»ts de transaction")
    report.append("- âœ… SÃ©lection d'actifs")
    report.append("")
    
    with open('results/evaluation_report.md', 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print("   âœ… Rapport sauvegardÃ©: results/evaluation_report.md")


if __name__ == "__main__":
    main()